---
title: "week2"
author: "kangzq"
date: "2021/8/22"
output:
  html_document:
    fig_height: 4
    highlight: pygments
    theme: spacelab
  pdf_document: default
---

## Hypothesis Testing

1. Null hypothesis: Represents a skeptical perspective or status.

2. Alternative hypothesis: Represents an alternative under consideration and is often represented by a range of possible parameter values.

### Construction of hypotheses

* Always construct hypotheses about population parameters. 

* Define the null value as the value the parameter is set to equal in the null hypothesis.

* Note that the alternative hypothesis might be one-sided (μ < or > the null value) or two-sided (μ≠ the null value), and the choice depends on the research question. 

### p-value

Define p-value as the conditional probability of getting a sample statistic at least as extreme as the one observed given that the null hypothesis is true. Calculate a p-value as the area under the normal curve beyond the observed sample mean (either in one tail or both, depending on the alternative hypothesis). 

* p−value=P(observed or more extreme sample statistic | H0 true)

* test statistic: z = (x - miu)/SE 

* Always sketch the normal curve when calculating the p-value, and shade the appropriate area(s) depending on whether the alternative hypothesis is one- or two-sided. 

If a confidence interval does not contain the null value the null hypothesis should be rejected in favor of the alternative. 

### Make a decision

Compare the p-value to the significance level to make a decision. 

* If the p-value < the significance level, reject the null hypothesis.

* If the p-value > the significance level, fail to reject the null hypothesis.

* Note that we can never “accept” the null hypothesis since the hypothesis testing framework does not allow us to confirm it. 

### Wrong decision

* Type 1 error: reject null hypothesis but the null hypothesis is actually true.

* Type 2 error: failing to reject the null hypothesis when the alternative hypothesis is actually true. 

The probability of making a Type 1 error is relevant to the significance level. A significance level should be chosen depending on the risks associated with type 1 and type 2 errors. 

* Use a smaller significance level (α) if Type 1 error is relatively riskier.

* Use a larger α if Type 2 error is relatively riskier. 



## Significance

Sampling distributions of point estimates coming from samples that don’t meet the required conditions for the CLT (about sample size, skew, and independence) will not be normal.

### Workflow of statistical inference

1. Set up the hypotheses first in plain language and then using appropriate notation.

2. Identify the appropriate sample statistic -- that can be used as a point estimate for the parameter of interest. 

3. Verify that the conditions for the CLT hold. 

4. Compute the SE (standard error), sketch the sampling distribution, and shade area(s) representing the p-value. 

5. Determine if the null hypothesis should be rejected or not, and state your conclusion in context of the data and the research question. 

### What should I do if not CLT?

Do not go forward with the previous analysis workflow. 
### Other informations

Calculate the required sample size to obtain a given margin of error at a given confidence level by working backwards from the given margin of error. 

Distinguish between statistical significance vs. practical significance. 

Define ```power``` as the probability of correctly rejecting the null hypothesis (complement of Type 2 error). 








# Week2 Lab

If you have access to data on an entire population, say the size of every house in Ames, Iowa, it's straight forward to answer questions like, "How big is the typical house in Ames?" and "How much variation is there in sizes of houses?". If you have access to only a sample of the population, as is often the case, the task becomes more complicated. What is your best guess for the typical size if you only know the sizes of several dozen houses? This sort of situation requires that you use your sample to make inference on what your population looks like.


**Setting a seed:** We will take some random samples and calculate confidence based on these samples in this lab, which means you should set a seed on top of your lab. If this concept is new to you, review the previous lab and ask your TA.

Setting a seed will cause R to sample the same sample each time you knit your document.This will make sure your results don't change each time you knit, and it will also ensure reproducibility of your work (by setting the same seed it will be possible to reproduce your results). You can set a seed like this:

```{r set-seed}
set.seed(910)                 # make sure to change the seed
```

The number above is completely arbitraty. If you need inspiration, you can use your ID, birthday, or just a random string of numbers. The important thing is that you use each seed only once. You only need to do this once in your R Markdown document, but make sure it comes before sampling.


## Getting Started

### Load packages

In this lab we will explore the data using the `dplyr` package and visualize it using the `ggplot2` package for data visualization. The data can be found in the companion package for this course, `statsr`.

Let's load the packages.

```{r load-packages, message=FALSE}
library(statsr)
library(dplyr)
library(ggplot2)
```

### The data

We consider real estate data from the city of Ames, Iowa. This is the same dataset used in the previous lab. The details of every real estate transaction in Ames is recorded by the City Assessor's office. Our particular focus for this lab will be all residential home sales in Ames between 2006 and 2010.  This collection represents our population of interest. In this lab we would like to learn about these home sales by taking smaller samples from the full population. Let's load the data.

```{r load-data}
data(ames)
```

In this lab we'll start with a simple random sample of size 60 from the population. Specifically, this is a simple random sample of size 60. Note that the data set has information on many housing variables, but for the first portion of the lab we'll focus on the size of the house, represented by the variable `area`.

```{r sample}
n <- 60
samp <- sample_n(ames, n)
```

**Exercise**: Describe the distribution of homes in your sample. What would you say is the "typical" size within your sample? Also state precisely what you interpreted "typical" to mean.

```{r describe-sample}
# type your code for the Exercise here, and Knit
samp %>%
  summarise(x_bar = mean(area), s = sd(area), 
            med_samp = median(area),
            min_samp = min(area), max_samp = max(area),
            iqr_samp = IQR(area),
            q1_samp = quantile(area, 0.25), 
            q3_samp = quantile(area, 0.75)) 
```

## Confidence intervals

Return for a moment to the question that first motivated this lab: based on this sample, what can we infer about the population? Based only on this single sample, the best estimate of the average living area of houses sold in Ames would be the sample mean, usually denoted as $\bar{x}$ (here we're calling it `x_bar`). That serves as a good **point estimate** but it would be useful to also communicate how uncertain we are of that estimate. This uncertainty can be quantified using a **confidence interval**.

A confidence interval for a population mean is of the following form \[ \bar{x} \pm z^\star \frac{s}{\sqrt{n}} \]

You should by now be comfortable with calculating the mean and standard deviation of a sample in R. And we know that the sample size is 60. So the only remaining building block is finding the appropriate critical value for a given confidence level. We can use the `qnorm` function for this task, which will give the critical value associated with a given percentile under the normal distribution. Remember that confidence levels and percentiles are not equivalent. For example, a 95% confidence level refers to the middle 95% of the distribution, and the critical value associated with this area will correspond to the 97.5th percentile.

We can find the critical value for a 95% confidence interal using

```{r z_star_95}
z_star_95 <- qnorm(0.975)
z_star_95
```

which is roughly equal to the value critical value 1.96 that you're likely familiar with by now.

Let's finally calculate the confidence interval:

```{r ci}
samp %>%
  summarise(lower = mean(area) - z_star_95 * (sd(area) / sqrt(n)),
            upper = mean(area) + z_star_95 * (sd(area) / sqrt(n)))
```

To recap: even though we don't know what the full population looks like, we're 95% confident that the true average size of houses in Ames lies between the values *lower* and *upper*. There are a few conditions that must be met for this interval to be valid.


## Confidence levels

In this case we have the rare luxury of knowing the true population mean since we have data on the entire population. Let's calculate this value so that we can determine if our confidence intervals actually capture it. We'll store it in a data frame called `params` (short for population parameters), and name it `mu`.

```{r pop-mean}
params <- ames %>%
  summarise(mu = mean(area))
params
```

**Exercise**: Does your confidence interval capture the true average size of houses in Ames?

```{r check-ci-contain-true-mean}
# type your code for the Exercise here, and Knit
samp %>%
  summarise(lower = mean(area) - z_star_95 * (sd(area) / sqrt(n)),
            upper = mean(area) + z_star_95 * (sd(area) / sqrt(n)))
```

Using R, we're going to collect many samples to learn more about how sample means and confidence intervals vary from one sample to another.

Here is the rough outline:

-   Obtain a random sample.
-   Calculate the sample's mean and standard deviation, and use these to calculate
and store the lower and upper bounds of the confidence intervals.
-   Repeat these steps 50 times.

We can accomplish this using the `rep_sample_n` function. The following lines of code takes 50 random samples of size `n` from population (and remember we defined $n = 60$ earlier), and computes the upper and lower bounds of the confidence intervals based on these samples.

```{r calculate-50-cis}
ci <- ames %>%
        rep_sample_n(size = n, reps = 50, replace = TRUE) %>%
        summarise(lower = mean(area) - z_star_95 * (sd(area) / sqrt(n)),
                  upper = mean(area) + z_star_95 * (sd(area) / sqrt(n)))

```

Let's view the first five intervals:

```{r first-five-intervals}
ci %>%
  slice(1:5)
```

Next we'll create a plot similar to Figure 4.8 on page 175 of [OpenIntro Statistics, 3rd Edition](https://www.openintro.org/os). First step will be to create a new variable in the `ci` data frame that indicates whether the interval does or does not capture the true population mean. Note that capturing this value would mean the lower bound of the confidence interval is below the value and upper bound of the confidence interval is above the value. Remember that we create new variables using the `mutate` function.

```{r capture-mu}
ci <- ci %>%
  mutate(capture_mu = ifelse(lower < params$mu & upper > params$mu, "yes", "no"))
```

The `ifelse` function is new. It takes three arguments: first is a logical statement, second is the value we want if the logical statement yields a true result, and the third is the value we want if the logical statement yields a false result.

We now have all the information we need to create the plot, but we need to re-organize our data a bit for easy plotting. Specifically, we need to organize the data in a new data frame where each row represents one bound, as opposed to one interval. So this

~~~
     lower    upper capture_mu
1 1350.540 1544.360        yes
2 1333.441 1584.425        yes
3 1412.133 1663.801        yes
...
~~~

should instead look like

~~~
  ci_id ci_bounds capture_mu
1     1  1350.540        yes
2     2  1333.441        yes
3     3  1412.133        yes
4     1  1544.360        yes
5     2  1584.425        yes
6     3  1663.801        yes
...
~~~

We can accomplish this using the following:

```{r create-ci-data-for-plot}
ci_data <- data.frame(ci_id = c(1:50, 1:50),
                      ci_bounds = c(ci$lower, ci$upper),
                      capture_mu = c(ci$capture_mu, ci$capture_mu))
```

And finally we can create the plot using the following:

```{r plot-ci}
ggplot(data = ci_data, aes(x = ci_bounds, y = ci_id, 
                           group = ci_id, color = capture_mu)) +
  geom_point(size = 2) +  # add points at the ends, size = 2
  geom_line() +           # connect with lines
  geom_vline(xintercept = params$mu, color = "darkgray") # draw vertical line
```

**Exercise**: What proportion of your confidence intervals include the true population mean? 
Is this proportion exactly equal to the confidence level? If not, explain why.


```{r find-99-perc-crit-val}
# type your code for the Question 5 here, and Knit
z_star_99 <- qnorm(0.995)
z_star_99
```


**Exercise**: Calculate 50 confidence intervals at the 99% confidence level. You do not need to obtain new samples, simply calculate new intervals based on the 95% confidence interval endpoints you had already collected. Plot all intervals and calculate the proportion of intervals that include the true population mean.

```{r plot-99-perc-cis}
# type your code for the Exercise here, and Knit
ci_99 <- ames %>%
        rep_sample_n(size = n, reps = 50, replace = TRUE) %>%
        summarise(lower = mean(area) - z_star_99 * (sd(area) / sqrt(n)),
                  upper = mean(area) + z_star_99 * (sd(area) / sqrt(n)))

ci_99 <- ci_99 %>%
  mutate(capture_mu = ifelse(lower < params$mu & upper > params$mu, "yes", "no"))

ci_data_99 <- data.frame(ci_id = c(1:50, 1:50),
                      ci_bounds = c(ci_99$lower, ci_99$upper),
                      capture_mu = c(ci_99$capture_mu, ci_99$capture_mu))

ggplot(data = ci_data_99, aes(x = ci_bounds, y = ci_id, 
                           group = ci_id, color = capture_mu)) +
  geom_point(size = 2) +  
  geom_line() +           
  geom_vline(xintercept = params$mu, color = "darkgray") 
```




